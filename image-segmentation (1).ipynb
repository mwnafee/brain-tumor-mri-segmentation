{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":407317,"sourceType":"datasetVersion","datasetId":181273},{"sourceId":6225023,"sourceType":"datasetVersion","datasetId":3575430}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install scikit-image","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:38:40.480356Z","iopub.execute_input":"2023-07-31T06:38:40.480683Z","iopub.status.idle":"2023-07-31T06:38:56.219444Z","shell.execute_reply.started":"2023-07-31T06:38:40.480653Z","shell.execute_reply":"2023-07-31T06:38:56.217818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.ndimage import label","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:38:56.222240Z","iopub.execute_input":"2023-07-31T06:38:56.222662Z","iopub.status.idle":"2023-07-31T06:38:56.318355Z","shell.execute_reply.started":"2023-07-31T06:38:56.222618Z","shell.execute_reply":"2023-07-31T06:38:56.317363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\nimport cv2\nfrom tqdm import tqdm_notebook, tnrange\nfrom glob import glob\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nimport skimage\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n#from utils import *\n#from unet import *","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-31T06:38:56.320066Z","iopub.execute_input":"2023-07-31T06:38:56.320815Z","iopub.status.idle":"2023-07-31T06:39:13.487330Z","shell.execute_reply.started":"2023-07-31T06:38:56.320759Z","shell.execute_reply":"2023-07-31T06:39:13.486119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#setting image parameters\nim_width= 256\nim_height= 256","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:39:13.490014Z","iopub.execute_input":"2023-07-31T06:39:13.490664Z","iopub.status.idle":"2023-07-31T06:39:13.495763Z","shell.execute_reply.started":"2023-07-31T06:39:13.490632Z","shell.execute_reply":"2023-07-31T06:39:13.494751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# loading the image and mask paths","metadata":{}},{"cell_type":"code","source":"image_filenames_train=[]\n# creating a list of all files containing the word 'mask'\nmask_files=glob('/kaggle/input/lgg-mri-segmentation/kaggle_3m/*/*_mask.tif')\nfor i in mask_files:\n    image_filenames_train.append(i.replace('_mask',''))\nprint(image_filenames_train[:10])\nlen(image_filenames_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:39:13.497072Z","iopub.execute_input":"2023-07-31T06:39:13.497980Z","iopub.status.idle":"2023-07-31T06:39:14.589276Z","shell.execute_reply.started":"2023-07-31T06:39:13.497945Z","shell.execute_reply":"2023-07-31T06:39:14.588167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_from_img_path(rows,columns,list_image_path,list_mask_path):\n    fig=plt.figure(figsize=(12,12))\n    for i in range(1,rows*columns+1):\n        fig.add_subplot(rows, columns, i)\n        img_path=list_image_path[i]\n        mask_path=list_mask_path[i]\n        image = cv2.imread(img_path)\n        image= cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n        mask=cv2.imread(mask_path)\n        mask= cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)\n        plt.imshow(image)\n        plt.imshow(mask,alpha=0.4)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:39:14.590946Z","iopub.execute_input":"2023-07-31T06:39:14.592068Z","iopub.status.idle":"2023-07-31T06:39:14.600673Z","shell.execute_reply.started":"2023-07-31T06:39:14.592020Z","shell.execute_reply":"2023-07-31T06:39:14.599640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_from_img_path(2,2,image_filenames_train,mask_files)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:39:14.602577Z","iopub.execute_input":"2023-07-31T06:39:14.603381Z","iopub.status.idle":"2023-07-31T06:39:16.200105Z","shell.execute_reply.started":"2023-07-31T06:39:14.603343Z","shell.execute_reply":"2023-07-31T06:39:16.198836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create dataframe and split data on train set, validation set and test set\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame(data={'image_filenames_train':image_filenames_train,'mask':mask_files})\ndf_train,df_test=train_test_split(df,test_size=0.1)\nprint(df_train.shape)\nprint(df_test.shape)\ndf_train,df_val=train_test_split(df_train,test_size=0.2)\nprint(df_train.shape)\nprint(df_val.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:39:16.201209Z","iopub.execute_input":"2023-07-31T06:39:16.201551Z","iopub.status.idle":"2023-07-31T06:39:16.226348Z","shell.execute_reply.started":"2023-07-31T06:39:16.201519Z","shell.execute_reply":"2023-07-31T06:39:16.225334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_and_diagnose(img, mask):\n    img = img / 255\n    mask = mask / 255\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    return(img, mask)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:39:16.227888Z","iopub.execute_input":"2023-07-31T06:39:16.228502Z","iopub.status.idle":"2023-07-31T06:39:16.234129Z","shell.execute_reply.started":"2023-07-31T06:39:16.228468Z","shell.execute_reply":"2023-07-31T06:39:16.232878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_generator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode='grayscale',\n                   mask_color_mode='grayscale',image_save_prefix=\"image\",mask_save_prefix=\"mask\",\n                   flag_multi_class=False,num_class=2,save_to_dir=None,target_size=(256,256),seed=1):\n    image_datagen=ImageDataGenerator(**aug_dict)\n    mask_datagen=ImageDataGenerator(**aug_dict)\n    image_generator=image_datagen.flow_from_director(\n        train_path,\n        classes=[image_folder],\n        class_mode=None,\n        target_size=target_size,\n        batch_size=batch_size,\n        save_to_dir=save_to_dir,\n        save_prefix=image_save_prefix,\n        seed=seed\n    )\n    mask_generator = mask_datagen.flow_from_dataframe(\n        train_path,\n        classes=[mask_folder],\n        class_mode=None,\n        color_mode=mask_color_mode,\n        target_size=target_size,\n        batch_size=batch_size,\n        save_to_dir=save_to_dir,\n        save_prefix=mask_save_prefix,\n        seed=seed,\n    )\n    \n    train_generator = zip(image_generator, mask_generator)\n    \n    # Final return Tuple after image Normalization and Diagnostics\n    for (img, mask) in train_generator:\n        img, mask = normalize_and_diagnose(img, mask)\n        yield (img, mask)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:39:16.238921Z","iopub.execute_input":"2023-07-31T06:39:16.239304Z","iopub.status.idle":"2023-07-31T06:39:16.249332Z","shell.execute_reply.started":"2023-07-31T06:39:16.239278Z","shell.execute_reply":"2023-07-31T06:39:16.248169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Referring Code From: https://github.com/zhixuhao/unet/blob/master/data.py\ndef train_generator(\n    data_frame,\n    batch_size,\n    augmentation_dict,\n    image_color_mode=\"rgb\",\n    mask_color_mode=\"grayscale\",\n    image_save_prefix=\"image\",\n    mask_save_prefix=\"mask\",\n    save_to_dir=None,\n    target_size=(256, 256),\n    seed=1,\n):\n    \"\"\"\n    can generate image and mask at the same time use the same seed for\n    image_datagen and mask_datagen to ensure the transformation for image\n    and mask is the same if you want to visualize the results of generator,\n    set save_to_dir = \"your path\"\n    \"\"\"\n    image_datagen = ImageDataGenerator(**augmentation_dict)\n    mask_datagen = ImageDataGenerator(**augmentation_dict)\n\n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col=\"image_filenames_train\",\n        class_mode=None,\n        color_mode=image_color_mode,\n        target_size=target_size,\n        batch_size=batch_size,\n        save_to_dir=save_to_dir,\n        save_prefix=image_save_prefix,\n        seed=seed,\n    )\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col=\"mask\",\n        class_mode=None,\n        color_mode=mask_color_mode,\n        target_size=target_size,\n        batch_size=batch_size,\n        save_to_dir=save_to_dir,\n        save_prefix=mask_save_prefix,\n        seed=seed,\n    )\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    # Final return Tuple after image Normalization and Diagnostics\n    for (img, mask) in train_gen:\n        img, mask = normalize_and_diagnose(img, mask)\n        yield (img, mask)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:39:16.251106Z","iopub.execute_input":"2023-07-31T06:39:16.251903Z","iopub.status.idle":"2023-07-31T06:39:16.262127Z","shell.execute_reply.started":"2023-07-31T06:39:16.251867Z","shell.execute_reply":"2023-07-31T06:39:16.261273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_coefficients(y_true,y_pred,smooth=100):\n    y_true_flatten=K.flatten(y_true)\n    y_pred_flatten=K.flatten(y_pred)\n    \n    intersection=K.sum(y_true_flatten*y_pred_flatten)\n    union=K.sum(y_true_flatten)+K.sum(y_pred_flatten)\n    return (2*intersection+smooth)/(union+smooth)\ndef dice_coefficient_loss(y_true,y_pred,smooth=100):\n    return -dice_coefficients(y_true,y_pred,smooth)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:39:16.263420Z","iopub.execute_input":"2023-07-31T06:39:16.266221Z","iopub.status.idle":"2023-07-31T06:39:16.280963Z","shell.execute_reply.started":"2023-07-31T06:39:16.266010Z","shell.execute_reply":"2023-07-31T06:39:16.279720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def iou(y_true, y_pred, smooth=100):\n    intersection = K.sum(y_true * y_pred)\n    sum = K.sum(y_true + y_pred)\n    iou = (intersection + smooth) / (sum - intersection + smooth)\n    return iou\ndef jaccard_distance(y_true, y_pred): #same as iou loss. This iou is jaccard iou\n    y_true_flatten = K.flatten(y_true)\n    y_pred_flatten = K.flatten(y_pred)\n    return -iou(y_true_flatten, y_pred_flatten)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:39:16.282651Z","iopub.execute_input":"2023-07-31T06:39:16.283056Z","iopub.status.idle":"2023-07-31T06:39:16.293265Z","shell.execute_reply.started":"2023-07-31T06:39:16.283009Z","shell.execute_reply":"2023-07-31T06:39:16.292116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unet(input_size=(256, 256, 3)):\n    \"\"\"\n    This function creates and returns a U-Net model. U-Net is a type of convolutional neural network\n    designed for fast and precise segmentation of images. It consists of a contracting (downsampling)\n    path and an expansive (upsampling) path, which gives it a U-shaped architecture.\n\n    Parameters:\n    -----------\n    input_size : tuple of int\n        The size of the input images. It is a 3-tuple for (height, width, channels).\n        Default is (256, 256, 3).\n\n    Returns:\n    --------\n    model : keras.models.Model\n        The constructed U-Net model.\n    \"\"\"\n    inputs = Input(input_size)\n\n    # First DownConvolution / Encoder Leg will begin, so start with Conv2D\n    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(inputs)\n    bn1 = Activation(\"relu\")(conv1)\n    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation(\"relu\")(bn1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(pool1)\n    bn2 = Activation(\"relu\")(conv2)\n    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation(\"relu\")(bn2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n\n    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(pool2)\n    bn3 = Activation(\"relu\")(conv3)\n    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation(\"relu\")(bn3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(pool3)\n    bn4 = Activation(\"relu\")(conv4)\n    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation(\"relu\")(bn4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\")(pool4)\n    bn5 = Activation(\"relu\")(conv5)\n    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\")(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation(\"relu\")(bn5)\n\n    \"\"\" Now UpConvolution / Decoder Leg will begin, so start with Conv2DTranspose\n    The gray arrows (in the above image) indicate the skip connections that concatenate the encoder feature map with the decoder, which helps the backward flow of gradients for improved training. \"\"\"\n    up6 = concatenate(\n        [\n            Conv2DTranspose(512, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(\n                bn5\n            ),\n            conv4,\n        ],\n        axis=3,\n    )\n    \"\"\" After every concatenation we again apply two consecutive regular convolutions so that the model can learn to assemble a more precise output \"\"\"\n    conv6 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(up6)\n    bn6 = Activation(\"relu\")(conv6)\n    conv6 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation(\"relu\")(bn6)\n\n    up7 = concatenate(\n        [\n            Conv2DTranspose(256, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(\n                bn6\n            ),\n            conv3,\n        ],\n        axis=3,\n    )\n    conv7 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(up7)\n    bn7 = Activation(\"relu\")(conv7)\n    conv7 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation(\"relu\")(bn7)\n\n    up8 = concatenate(\n        [\n            Conv2DTranspose(128, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(\n                bn7\n            ),\n            conv2,\n        ],\n        axis=3,\n    )\n    conv8 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(up8)\n    bn8 = Activation(\"relu\")(conv8)\n    conv8 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation(\"relu\")(bn8)\n\n    up9 = concatenate(\n        [\n            Conv2DTranspose(64, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(\n                bn8\n            ),\n            conv1,\n        ],\n        axis=3,\n    )\n    conv9 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(up9)\n    bn9 = Activation(\"relu\")(conv9)\n    conv9 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation(\"relu\")(bn9)\n\n    conv10 = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\")(bn9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:39:16.296332Z","iopub.execute_input":"2023-07-31T06:39:16.297141Z","iopub.status.idle":"2023-07-31T06:39:16.324963Z","shell.execute_reply.started":"2023-07-31T06:39:16.297095Z","shell.execute_reply":"2023-07-31T06:39:16.324017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 100\nBATCH_SIZE = 32\nlearning_rate = 1e-4\nsmooth=100","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:39:16.326867Z","iopub.execute_input":"2023-07-31T06:39:16.327123Z","iopub.status.idle":"2023-07-31T06:39:16.341977Z","shell.execute_reply.started":"2023-07-31T06:39:16.327100Z","shell.execute_reply":"2023-07-31T06:39:16.341009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet()\nmodel.summary()\n\ntf.keras.utils.plot_model(\n    model,\n    show_shapes=True,\n    show_dtype=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:39:16.343900Z","iopub.execute_input":"2023-07-31T06:39:16.344333Z","iopub.status.idle":"2023-07-31T06:39:23.635642Z","shell.execute_reply.started":"2023-07-31T06:39:16.344287Z","shell.execute_reply":"2023-07-31T06:39:23.634748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator_param=dict(rotation_range=0.2,\n                          width_shift_range=0.05,\n                           shear_range=0.05,\n                           zoom_range=0.05,\n                           horizontal_flip=True,\n                           fill_mode='nearest')\ntrain_gen=train_generator(df_train,BATCH_SIZE,train_generator_param,target_size=(im_height,im_width))\ntest_gen=train_generator(df_train,BATCH_SIZE,dict(),target_size=(im_height,im_width))\nmodel = unet(input_size=[im_height, im_width,3])\ndecay_rate=learning_rate/EPOCHS\noptimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate,beta_1=0.9,beta_2=0.999,epsilon=None,decay=decay_rate,amsgrad=False)\nmodel.compile(optimizer=optimizer,loss=dice_coefficient_loss,metrics=['binary_accuracy',iou,dice_coefficients])\ncallbacks=[ModelCheckpoint('unet.hdf5',verbose=1,save_best_only=True)]\nhistory= model.fit(train_gen,\n                   steps_per_epoch=len(df_train)/BATCH_SIZE,\n                   epochs=EPOCHS,\n                   callbacks=callbacks,\n                   validation_data=test_gen,\n                   validation_steps=len(df_test)/BATCH_SIZE\n                   )\n","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:39:23.636908Z","iopub.execute_input":"2023-07-31T06:39:23.637775Z","iopub.status.idle":"2023-07-31T10:46:56.742093Z","shell.execute_reply.started":"2023-07-31T06:39:23.637740Z","shell.execute_reply":"2023-07-31T10:46:56.740851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_post_training = history.history\n\ntrain_dice_coeff_list = history_post_training['dice_coefficients']\ntest_dice_coeff_list = history_post_training['val_dice_coefficients']\n\ntrain_jaccard_list = history_post_training['iou']\ntest_jaccard_list = history_post_training['val_iou']\n\ntrain_loss_list = history_post_training['loss']\ntest_loss_list = history_post_training['val_loss']\n\nplt.figure(1)\nplt.plot(test_loss_list, 'b-')\nplt.plot(train_loss_list, 'r-')\n\nplt.xlabel('iterations')\nplt.ylabel('loss')\nplt.title('loss graph', fontsize=12)\n\nplt.figure(2)\nplt.plot(train_dice_coeff_list, 'b-')\nplt.plot(test_dice_coeff_list, 'r-')\n\nplt.xlabel('iterations')\nplt.ylabel('accuracy')\nplt.title('Accuracy graph', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:03:09.938264Z","iopub.execute_input":"2023-07-31T11:03:09.938832Z","iopub.status.idle":"2023-07-31T11:03:10.740937Z","shell.execute_reply.started":"2023-07-31T11:03:09.938770Z","shell.execute_reply":"2023-07-31T11:03:10.737412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(20):\n    index = np.random.randint(1, len(df_test.index))\n    img = cv2.imread(df_test['image_filenames_train'].iloc[index])\n    img = cv2.resize(img, (im_height, im_width))\n    img = img/255\n    # print(imgs.shape) (256, 256 , 3)\n    img = img[np.newaxis, :, :, : ]\n    # print(img.shape) # (1, 256, 256, 3)\n\n    predicted_img = model.predict(img)\n    \n    plt.figure(figsize=(12, 12))\n    plt.subplot(1, 3, 1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n\n    plt.subplot(1, 3, 2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask'].iloc[index])))\n    plt.title('Original Mask')\n\n    plt.subplot(1, 3, 3)\n    plt.imshow(np.squeeze(predicted_img) > 0.5 )\n    plt.title('Prediction')\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:08:25.691767Z","iopub.execute_input":"2023-07-31T11:08:25.692223Z","iopub.status.idle":"2023-07-31T11:08:44.139628Z","shell.execute_reply.started":"2023-07-31T11:08:25.692189Z","shell.execute_reply":"2023-07-31T11:08:44.138597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('unet.hdf5', custom_objects={'dice_coefficient_loss': dice_coefficient_loss, 'iou': iou, 'dice_coefficient': dice_coefficients  } ,compile=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:54:00.806573Z","iopub.execute_input":"2023-07-31T11:54:00.806976Z","iopub.status.idle":"2023-07-31T11:54:01.597871Z","shell.execute_reply.started":"2023-07-31T11:54:00.806944Z","shell.execute_reply":"2023-07-31T11:54:01.596826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(8):\n    index = np.random.randint(1, len(df_test.index))\n    img = cv2.imread(df_test['image_filenames_train'].iloc[index])\n    img = cv2.resize(img, (im_height, im_width))\n    img = img/255\n    # print(imgs.shape) (256, 256 , 3)\n    img = img[np.newaxis, :, :, : ]\n    # print(img.shape) # (1, 256, 256, 3)\n\n    predicted_img = model.predict(img)\n    \n    plt.figure(figsize=(12, 12))\n    plt.subplot(1, 3, 1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n\n    plt.subplot(1, 3, 2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask'].iloc[index])))\n    plt.title('Original Mask')\n\n    plt.subplot(1, 3, 3)\n    plt.imshow(np.squeeze(predicted_img) > 0.5 )\n    plt.title('Prediction')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:54:39.275048Z","iopub.execute_input":"2023-07-31T11:54:39.275421Z","iopub.status.idle":"2023-07-31T11:54:45.966013Z","shell.execute_reply.started":"2023-07-31T11:54:39.275390Z","shell.execute_reply":"2023-07-31T11:54:45.964746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('/kaggle/input/unethdf5/unet.hdf5', custom_objects={'dice_coefficient_loss': dice_coefficient_loss, 'iou': iou, 'dice_coefficient': dice_coefficients  } ,compile=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:57:19.505949Z","iopub.execute_input":"2023-07-31T11:57:19.506340Z","iopub.status.idle":"2023-07-31T11:57:22.108350Z","shell.execute_reply.started":"2023-07-31T11:57:19.506311Z","shell.execute_reply":"2023-07-31T11:57:22.107158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(7):\n    index = np.random.randint(1, len(df_test.index))\n    img = cv2.imread(df_test['image_filenames_train'].iloc[index])\n    img = cv2.resize(img, (im_height, im_width))\n    img = img/255\n    # print(imgs.shape) (256, 256 , 3)\n    img = img[np.newaxis, :, :, : ]\n    # print(img.shape) # (1, 256, 256, 3)\n\n    predicted_img = model.predict(img)\n    \n    plt.figure(figsize=(12, 12))\n    plt.subplot(1, 3, 1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n\n    plt.subplot(1, 3, 2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask'].iloc[index])))\n    plt.title('Original Mask')\n\n    plt.subplot(1, 3, 3)\n    plt.imshow(np.squeeze(predicted_img) > 0.5 )\n    plt.title('Prediction')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:57:36.631256Z","iopub.execute_input":"2023-07-31T11:57:36.631649Z","iopub.status.idle":"2023-07-31T11:57:43.813530Z","shell.execute_reply.started":"2023-07-31T11:57:36.631617Z","shell.execute_reply":"2023-07-31T11:57:43.812569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}